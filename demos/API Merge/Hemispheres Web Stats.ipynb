{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will clean web statistics data by:\n",
    "#\n",
    "# 1) read a csv file containing web statistics from a hemispheres.com web site for an art gallery company\n",
    "# 2) profile the dataset\n",
    "# 3) identify important missing data\n",
    "# 4) access a third party API to supply missing location data\n",
    "# 5) update the web statistics data with the API's location data\n",
    "# 6) compare the before and after missing data is supplied to prove the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling # a very useful and powerful package - https://github.com/ydataai/pandas-profiling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21151ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_stats_df = pd.read_csv(\"statz_CSV_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather some information about the web stats file and save it for a later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c23a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "web_stats_profile_report = web_stats_df.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a178c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some sample rows from the web_stats dataframe to better see its file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_stats_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b241cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and print a count of all missing values. This will serve as control counts to compare with our work below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f723fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values_count = web_stats_df.isnull().sum()\n",
    "missing_values_count[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669111bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate total cells of the web status data frame, sum up the missing values and report the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_stats_total_cells = np.product(web_stats_df.shape)\n",
    "web_stats_total_missing_values = missing_values_count.sum()\n",
    "(web_stats_total_missing_values/web_stats_total_cells) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the process of filling in some of the most important missing data using data returned from an API call \n",
    "# to the IP-API public site\n",
    "\n",
    "# Set up request to the ip-api.com API\n",
    "\n",
    "## We are only doing 4 for demonstration purposes because more might incur costs.\n",
    "##\n",
    "## If we were going to fix all the missing values in web_stats_df we would select all of the web stat rows with \n",
    "## missing data \n",
    "## with something like this: \n",
    "##\n",
    "##    web_stats_null_rows_df = web_stats_df[web_stats_df['CITY'].isnull() | web_stats_df['REGION'].isnull() \n",
    "##     | web_stats_df['REGIONCODE'].isnull() | web_stats_df['COUNTRY'].isnull()]\n",
    "##\n",
    "## and send all of the IP values in the API request instead of only four. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "url = \"http://ip-api.com/batch?fields=status,message,country,region,regionName,city,zip,query\"\n",
    "\n",
    "#Build payload for request. \n",
    "payload = \"[\\\"154.54.249.207\\\", \\\"91.198.174.192\\\", \\\"141.98.81.23\\\", \\\"66.249.75.38\\\"]\"\n",
    "\n",
    "#Create content-type header for request. We're sending the request payload as plain text\n",
    "headers = {\n",
    "  'Content-Type': 'text/plain'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the header and payload using a POST request, check the response status code (200 = OK) \n",
    "# and, if there's an exception, print the raw json response payload since it's small so we can see what we're \n",
    "# dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status code {response.status_code}')  \n",
    "\n",
    "except Exception as e:\n",
    "    print('http status code = ' + str(response.status_code))\n",
    "    print('response json payload = ' + response.text)\n",
    "    print('Request failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df490f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the json response payload text into a pandas dictionary, create a pandas dataframe from the dictionary \n",
    "# and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500056d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locations = json.loads(response.text)\n",
    "\n",
    "location_df = pd.DataFrame(locations)\n",
    "\n",
    "print(location_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03068af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename region of the location_df columns to the same name of the web_stats_df. \n",
    "# We have to do this in 2 steps because there's a name colision with region.\n",
    "location_df.rename(columns={\"region\": \"REGIONCODE\"}, inplace = True)\n",
    "\n",
    "# rename some of the location_df columns to the same name of the web_stats_df columns for easier handling\n",
    "location_df.rename(columns={\"country\": \"COUNTRY\", \"regionName\": \"REGION\", \"city\": \"CITY\", \"zip\": \"ZIP\", \"query\": \"IP\"}, \n",
    "                   inplace = True)\n",
    "\n",
    "print(location_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ba222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code first defines a list called missing_cols that contains the column names 'COUNTRY', 'REGION', and 'CITY'.\n",
    "\n",
    "# The code then uses a for loop to iterate through the rows of web_stats_df. \n",
    "# For each row, the code checks if any of the columns in the missing_cols list contain a null value. \n",
    "# If any of the columns do contain a null value, the code uses the IP value in the current row of web_stats_df to \n",
    "# find the corresponding row in the location_df DataFrame.\n",
    "\n",
    "# Once the matching row is found, the code then updates the null values in the web_stats_df DataFrame with the data \n",
    "# from the matching row in the location_df DataFrame. \n",
    "# This process is repeated for each row in the web_stats_df DataFrame until all of the missing columns have been filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa55706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the columns that need to be filled\n",
    "missing_cols = ['COUNTRY', 'REGIONCODE', 'REGION', 'CITY']\n",
    "matched = 0\n",
    "replaced = 0\n",
    "\n",
    "# Loop through the rows in the first DataFrame\n",
    "for index, row in web_stats_df.iterrows():\n",
    "    \n",
    "    # Check if any of the missing columns have a null value\n",
    "    if row[missing_cols].isnull().any():\n",
    "        \n",
    "        # Get the corresponding row from the location_df dataFrame based on the IP value\n",
    "        match = location_df[location_df['IP'] == row['IP']]\n",
    "        if not match.empty:\n",
    "            print(\"found IP match\")\n",
    "            matched = matched + 1\n",
    "            # Update the missing columns with the data from the matching row\n",
    "            for col in missing_cols:\n",
    "                if pd.isnull(row[col]):\n",
    "                    web_stats_df.loc[index, col] = match.iloc[0][col]\n",
    "                    print(\"replaced : \" + web_stats_df[index, col])\n",
    "                    replaced = replaced + 1\n",
    "                else:\n",
    "                    print(\"not replaced : \" + web_stats_df[index, col])\n",
    "                    \n",
    "print(\"Matched = \" + str(matched))\n",
    "print(\"Replaced = \" + str(replaced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = web_stats_df.isnull().sum()\n",
    "missing_values_count[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_web_stats_profile_report = web_stats_df.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55179a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the original web_stats_profile_report that we created at the beginning to this one\n",
    "comparison_report = updated_web_stats_profile_report.compare(web_stats_profile_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_report.to_file(\"comparison.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aff954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "722b6f501d3291d098eeb116c55030d7476387c4156a20534e17b28f07582bab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
